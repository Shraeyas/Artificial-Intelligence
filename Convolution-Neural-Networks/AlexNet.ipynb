{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "781312a3-0a09-450b-9458-fb544fc09ab8",
   "metadata": {},
   "source": [
    "# **Alexnet**\n",
    "```\n",
    "Alexnet has 8 layers\n",
    "Theres 5 Convolution Layers, and 3 Fully Connected Layers\n",
    "```\n",
    "```\n",
    "The features that make alexnet special are :\n",
    "1. ReLU :\n",
    "   Alexnet uses ReLU instead of tanh. ReLU helps in improving training time.\n",
    "2. Data Augmentation :\n",
    "   a. Data is artificially created by rotating, flipping or zooming (etc.) into images.\n",
    "   b. They first performed PCA on the RGB pixels of the entire ImageNet training dataset.\n",
    "      They extracted the principal components for each of the channels.\n",
    "      They then add a random fraction of these principal components into each pixel of the image.\n",
    "      What it does to the image is that it changes the colour and intensity of the illumination.\n",
    "      Thus, it exploits a property of natural images that the label of the object is invariant of the illumination\n",
    "      parameters.\n",
    "3. Dropout Regularization :\n",
    "   Certain percentage of nodes (50%) are ignored.\n",
    "   Every iteration works on different set of nodes and each neuron will have different features to be extracted.\n",
    "   However, it will also increase the time required for training the model.\n",
    "```\n",
    "##### **Source : https://towardsdatascience.com/alexnet-8b05c5eb88d4**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2140f143-6135-40f3-ae20-553db5cb2a86",
   "metadata": {},
   "source": [
    "##### **Refer this link on how to implement the pre-built AlexNet**\n",
    "##### **https://analyticsindiamag.com/hands-on-guide-to-implementing-alexnet-with-keras-for-multi-class-image-classification/**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "739b9145-f1cf-4e6d-8295-5e39c41867cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15af5f4e-6060-45be-b487-d6b818a305b9",
   "metadata": {},
   "source": [
    "##### **Some Definitions**\n",
    "```\n",
    "Training Dataset : This is the group of our dataset used to train the neural network directly. Training data refers to the dataset partition exposed to the neural network during training.\n",
    "Validation Dataset : This group of the dataset is utilized during training to assess the performance of the network at various iterations.\n",
    "Test Dataset : This partition of the dataset evaluates the performance of our network after the completion of the training phase.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f99ad794-6268-4bf4-876b-96fb43ea24a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_x, train_y), (test_x, test_y) = keras.datasets.cifar10.load_data ()\n",
    "train_x = train_x [:5000]\n",
    "train_y = train_y [:5000]\n",
    "test_x = test_x [:500]\n",
    "test_y = test_y [:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "79fb5b7a-6fad-4e10-9e68-a20e07aa2584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 32, 32, 3) (5000, 1) (500, 32, 32, 3) (500, 1)\n"
     ]
    }
   ],
   "source": [
    "print (train_x.shape, train_y.shape, test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5e1c05-3b25-4078-b656-598d1b56a032",
   "metadata": {},
   "source": [
    "#### **Reshape the images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "419db8c2-0d6c-4509-8a24-1678abb42eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 224, 224, 3) (5000, 1) (500, 224, 224, 3) (500, 1)\n"
     ]
    }
   ],
   "source": [
    "train_x = tf.image.resize (train_x, [224, 224]).numpy ()\n",
    "test_x = tf.image.resize (test_x, [224, 224]).numpy ()\n",
    "\n",
    "print (train_x.shape, train_y.shape, test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "70f8c974-77b8-49c5-9118-72337c6839c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASS_NAMES = ['airplane',\n",
    "               'automobile',\n",
    "               'bird',\n",
    "               'cat',\n",
    "               'deer',\n",
    "               'dog',\n",
    "               'frog',\n",
    "               'horse',\n",
    "               'ship',\n",
    "               'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ad5b99de-c3c1-4957-95fa-42bbef87fd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer0 = keras.layers.Conv2D (filters = 96, kernel_size = (11, 11), strides = (4, 4), activation = 'relu', input_shape = (224, 224, 3))\n",
    "layer1 = keras.layers.BatchNormalization ()\n",
    "layer2 = keras.layers.MaxPool2D (pool_size = (3, 3), strides = (2, 2))\n",
    "layer3 = keras.layers.Conv2D (filters = 256, kernel_size = (5, 5), strides = (1, 1), activation = 'relu', padding = \"same\")\n",
    "layer4 = keras.layers.BatchNormalization ()\n",
    "layer5 = keras.layers.MaxPool2D (pool_size = (3, 3), strides = (2, 2))\n",
    "layer6 = keras.layers.Conv2D (filters = 384, kernel_size = (3, 3), strides = (1, 1), activation = 'relu', padding = \"same\")\n",
    "layer7 = keras.layers.BatchNormalization ()\n",
    "layer8 = keras.layers.Conv2D (filters = 384, kernel_size = (3, 3), strides = (1, 1), activation = 'relu', padding = \"same\")\n",
    "layer9 = keras.layers.BatchNormalization ()\n",
    "layer10 = keras.layers.Conv2D (filters = 256, kernel_size = (3, 3), strides = (1, 1), activation = 'relu', padding = \"same\")\n",
    "layer11 = keras.layers.BatchNormalization ()\n",
    "layer12 = keras.layers.MaxPool2D (pool_size = (3, 3), strides = (2, 2))\n",
    "layer13 = keras.layers.Flatten ()\n",
    "layer14 = keras.layers.Dense (4096, activation = 'relu')\n",
    "layer15 = keras.layers.Dropout (0.5)\n",
    "layer16 = keras.layers.Dense (4096, activation = 'relu')\n",
    "layer17 = keras.layers.Dropout (0.5)\n",
    "layer18 = keras.layers.Dense (10, activation = 'softmax')\n",
    "\n",
    "layers = [layer0, layer1, layer2, layer3, layer4, layer5, layer6, layer7, layer8,\n",
    "          layer9, layer10, layer11, layer12, layer13, layer14, layer15, layer16, layer17, layer18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "85ca9d64-bfc2-4412-9780-6d896c60c09f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 54, 54, 96)        34944     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 54, 54, 96)        384       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 26, 26, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 26, 26, 256)       614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 26, 26, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 12, 12, 384)       885120    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 12, 12, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 12, 12, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 12, 12, 384)       1536      \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 12, 12, 256)       884992    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 4096)              26218496  \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 46,793,482\n",
      "Trainable params: 46,790,730\n",
      "Non-trainable params: 2,752\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.Sequential (layers)\n",
    "model.compile (optimizer = tf.keras.optimizers.SGD (learning_rate = 0.01, momentum = 0.9),\n",
    "               loss = keras.losses.sparse_categorical_crossentropy,\n",
    "               metrics = ['accuracy', tf.keras.metrics.TopKCategoricalAccuracy (5)])\n",
    "\n",
    "model.summary ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4805d3e7-e8ae-4169-9c6f-430740550db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit (train_x,\n",
    "           train_y,\n",
    "           batch_size = 256,\n",
    "           epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d40d80f-ab3a-47b4-a145-6fde364850b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
